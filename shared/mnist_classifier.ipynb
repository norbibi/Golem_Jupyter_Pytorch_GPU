{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3b2fc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:03<00:00, 2508387.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 22946712.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 16868850.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 3090611.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | Sequential         | 55.1 K\n",
      "1 | val_accuracy  | MulticlassAccuracy | 0     \n",
      "2 | test_accuracy | MulticlassAccuracy | 0     \n",
      "-----------------------------------------------------\n",
      "55.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.1 K    Total params\n",
      "0.220     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/venv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 15 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/venv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 15 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 215/215 [00:07<00:00, 28.85it/s, v_num=0]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▌         | 1/20 [00:00<00:00, 272.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█         | 2/20 [00:00<00:00, 52.11it/s] \u001b[A\n",
      "Validation DataLoader 0:  15%|█▌        | 3/20 [00:00<00:00, 41.26it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 4/20 [00:00<00:00, 37.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██▌       | 5/20 [00:00<00:00, 35.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|███       | 6/20 [00:00<00:00, 33.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|███▌      | 7/20 [00:00<00:00, 33.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 8/20 [00:00<00:00, 32.50it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████▌     | 9/20 [00:00<00:00, 32.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████     | 10/20 [00:00<00:00, 31.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████▌    | 11/20 [00:00<00:00, 31.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 12/20 [00:00<00:00, 31.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|██████▌   | 13/20 [00:00<00:00, 31.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|███████   | 14/20 [00:00<00:00, 30.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|███████▌  | 15/20 [00:00<00:00, 30.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 16/20 [00:00<00:00, 30.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|████████▌ | 17/20 [00:00<00:00, 30.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|█████████ | 18/20 [00:00<00:00, 30.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████▌| 19/20 [00:00<00:00, 30.40it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████| 215/215 [00:08<00:00, 26.37it/s, v_num=0, val_loss=0.424, val_acc=0.884]\n",
      "Epoch 1: 100%|██████████| 215/215 [00:07<00:00, 28.86it/s, v_num=0, val_loss=0.424, val_acc=0.884]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▌         | 1/20 [00:00<00:00, 276.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█         | 2/20 [00:00<00:00, 51.52it/s] \u001b[A\n",
      "Validation DataLoader 0:  15%|█▌        | 3/20 [00:00<00:00, 41.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 4/20 [00:00<00:00, 37.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██▌       | 5/20 [00:00<00:00, 35.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|███       | 6/20 [00:00<00:00, 34.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|███▌      | 7/20 [00:00<00:00, 33.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 8/20 [00:00<00:00, 32.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████▌     | 9/20 [00:00<00:00, 32.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████     | 10/20 [00:00<00:00, 31.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████▌    | 11/20 [00:00<00:00, 31.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 12/20 [00:00<00:00, 31.41it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|██████▌   | 13/20 [00:00<00:00, 31.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|███████   | 14/20 [00:00<00:00, 31.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|███████▌  | 15/20 [00:00<00:00, 30.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 16/20 [00:00<00:00, 30.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|████████▌ | 17/20 [00:00<00:00, 30.73it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|█████████ | 18/20 [00:00<00:00, 30.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████▌| 19/20 [00:00<00:00, 30.56it/s]\u001b[A\n",
      "Epoch 1: 100%|██████████| 215/215 [00:08<00:00, 26.39it/s, v_num=0, val_loss=0.304, val_acc=0.909]\n",
      "Epoch 2: 100%|██████████| 215/215 [00:07<00:00, 29.09it/s, v_num=0, val_loss=0.304, val_acc=0.909]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▌         | 1/20 [00:00<00:00, 278.41it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█         | 2/20 [00:00<00:00, 54.39it/s] \u001b[A\n",
      "Validation DataLoader 0:  15%|█▌        | 3/20 [00:00<00:00, 43.26it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 4/20 [00:00<00:00, 38.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██▌       | 5/20 [00:00<00:00, 36.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|███       | 6/20 [00:00<00:00, 35.55it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|███▌      | 7/20 [00:00<00:00, 34.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 8/20 [00:00<00:00, 34.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████▌     | 9/20 [00:00<00:00, 33.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████     | 10/20 [00:00<00:00, 33.26it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████▌    | 11/20 [00:00<00:00, 32.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 12/20 [00:00<00:00, 32.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|██████▌   | 13/20 [00:00<00:00, 32.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|███████   | 14/20 [00:00<00:00, 32.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|███████▌  | 15/20 [00:00<00:00, 32.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 16/20 [00:00<00:00, 32.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|████████▌ | 17/20 [00:00<00:00, 31.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|█████████ | 18/20 [00:00<00:00, 31.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████▌| 19/20 [00:00<00:00, 31.76it/s]\u001b[A\n",
      "Epoch 2: 100%|██████████| 215/215 [00:08<00:00, 26.49it/s, v_num=0, val_loss=0.257, val_acc=0.921]\n",
      "Epoch 2: 100%|██████████| 215/215 [00:08<00:00, 26.46it/s, v_num=0, val_loss=0.257, val_acc=0.921]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 215/215 [00:08<00:00, 26.16it/s, v_num=0, val_loss=0.257, val_acc=0.921]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import lightning as L\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import torch\n",
    "from IPython.display import display\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchmetrics import Accuracy\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "PATH_DATASETS = os.environ.get(\"PATH_DATASETS\", \".\")\n",
    "BATCH_SIZE = 256 if torch.cuda.is_available() else 64\n",
    "\n",
    "class LitMNIST(L.LightningModule):\n",
    "    def __init__(self, data_dir=PATH_DATASETS, hidden_size=64, learning_rate=2e-4):\n",
    "        super().__init__()\n",
    "\n",
    "        # Set our init args as class attributes\n",
    "        self.data_dir = data_dir\n",
    "        self.hidden_size = hidden_size\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # Hardcode some dataset specific attributes\n",
    "        self.num_classes = 10\n",
    "        self.dims = (1, 28, 28)\n",
    "        channels, width, height = self.dims\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.1307,), (0.3081,)),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Define PyTorch model\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(channels * width * height, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_size, self.num_classes),\n",
    "        )\n",
    "\n",
    "        self.val_accuracy = Accuracy(task=\"multiclass\", num_classes=10)\n",
    "        self.test_accuracy = Accuracy(task=\"multiclass\", num_classes=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.val_accuracy.update(preds, y)\n",
    "\n",
    "        # Calling self.log will surface up scalars for you in TensorBoard\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", self.val_accuracy, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.test_accuracy.update(preds, y)\n",
    "\n",
    "        # Calling self.log will surface up scalars for you in TensorBoard\n",
    "        self.log(\"test_loss\", loss, prog_bar=True)\n",
    "        self.log(\"test_acc\", self.test_accuracy, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    ####################\n",
    "    # DATA RELATED HOOKS\n",
    "    ####################\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # download\n",
    "        MNIST(self.data_dir, train=True, download=True)\n",
    "        MNIST(self.data_dir, train=False, download=True)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            mnist_full = MNIST(self.data_dir, train=True, transform=self.transform)\n",
    "            self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])\n",
    "\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == \"test\" or stage is None:\n",
    "            self.mnist_test = MNIST(self.data_dir, train=False, transform=self.transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.mnist_train, batch_size=BATCH_SIZE)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.mnist_val, batch_size=BATCH_SIZE)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.mnist_test, batch_size=BATCH_SIZE)\n",
    "    \n",
    "model = LitMNIST()\n",
    "trainer = L.Trainer(\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    max_epochs=3,\n",
    "    logger=CSVLogger(save_dir=\"logs/\"),\n",
    ")\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4639189",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18aa0919",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
